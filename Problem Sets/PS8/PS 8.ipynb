{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46fca851-4392-44f9-9556-2b2a48667004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2617ae-dcc1-42bd-be0b-8bad1243abb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Is COMPAS fair? (50pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3de51d-9c60-4e98-b0b1-c0a62f092176",
   "metadata": {},
   "source": [
    "### 1.1 Load and prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4ac8b7-f15b-408e-9f1d-ba111de5276a",
   "metadata": {},
   "source": [
    "#### 1.1.1. (1pt) Load the COMPAS data, and perform the basic checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5692cd3a-ab91-472d-8ecc-2737d7d926f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows, Columns: (6172, 8)\n",
      "\n",
      "Column Types\n",
      "age                 int64\n",
      "c_charge_degree    object\n",
      "race               object\n",
      "age_cat            object\n",
      "sex                object\n",
      "priors_count        int64\n",
      "decile_score        int64\n",
      "two_year_recid      int64\n",
      "dtype: object\n",
      "\n",
      "Number of NaN values in each column\n",
      "age                0\n",
      "c_charge_degree    0\n",
      "race               0\n",
      "age_cat            0\n",
      "sex                0\n",
      "priors_count       0\n",
      "decile_score       0\n",
      "two_year_recid     0\n",
      "dtype: int64\n",
      "\n",
      "Sample\n",
      "      age c_charge_degree              race          age_cat   sex  \\\n",
      "3984   54               F         Caucasian  Greater than 45  Male   \n",
      "3179   31               F  African-American          25 - 45  Male   \n",
      "5484   22               F  African-American     Less than 25  Male   \n",
      "\n",
      "      priors_count  decile_score  two_year_recid  \n",
      "3984             2             4               1  \n",
      "3179             4             8               1  \n",
      "5484             3             6               1  \n"
     ]
    }
   ],
   "source": [
    "compas = pd.read_csv(\"compas-score-data.csv.bz2\", sep=\"\\t\")\n",
    "print(f\"Rows, Columns: {compas.shape}\")\n",
    "print(\"\\nColumn Types\")\n",
    "print(compas.dtypes)\n",
    "print(\"\\nNumber of NaN values in each column\")\n",
    "print(compas.isna().sum())\n",
    "print(\"\\nSample\")\n",
    "print(compas.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e613871-77fa-45ee-a4d7-6256824834aa",
   "metadata": {},
   "source": [
    "#### 1.1.2. (1pt) Filter the data to keep only Caucasian and African-Americans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e3201c-888e-4ee7-bf6a-73de3b38a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "compas = compas[(compas.race == \"African-American\") | (compas.race == \"Caucasian\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3906e5-fc7c-4b27-b43a-2325ebaea4a6",
   "metadata": {},
   "source": [
    "#### 1.1.3. (2pt) Create a new dummy variable based off of COMPAS risk score (decile_score), which indicates if an individual was classified as low risk (score 1-4) or high risk (score 5-10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5a9ed6-9d32-4745-b199-2c1fc079a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compas[\"highscore\"] = np.where(compas.decile_score <= 4, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6038824-aaf1-4bc2-af7f-5c87bf00d9db",
   "metadata": {},
   "source": [
    "#### 1.1.4. (4pt) Now analyze the offenders across this new risk category:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f532dd40-0694-4061-ba0e-84cf49218c1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### (a) What is the recidivism rate (percentage of offenders who re-commit the crime) for low- risk and high-risk individuals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "006ef321-4d0c-41c1-b637-c4ee1df6102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Risk Recidivism Rate: 32.00145296040683%\n",
      "High Risk Recidivism Rate: 63.445544554455445%\n"
     ]
    }
   ],
   "source": [
    "low_risk_rate = (compas[compas.highscore == 0].two_year_recid == 1).mean()\n",
    "print(f\"Low Risk Recidivism Rate: {low_risk_rate * 100}%\")\n",
    "high_risk_rate = (compas[compas.highscore == 1].two_year_recid == 1).mean()\n",
    "print(f\"High Risk Recidivism Rate: {high_risk_rate * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c317395-98c1-4028-a6b4-612db1fc1dcf",
   "metadata": {},
   "source": [
    "#### (b) What are the recidivism rates for African-Americans and Caucasians?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10371f05-3424-4e9b-ab7b-8a5891a1c0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "African-American Recidivism Rate: 52.31496062992126%\n",
      "Caucasians Risk Rate: 39.08701854493581%\n"
     ]
    }
   ],
   "source": [
    "aa_risk_rate = (compas[compas.race == \"African-American\"].two_year_recid == 1).mean()\n",
    "print(f\"African-American Recidivism Rate: {aa_risk_rate * 100}%\")\n",
    "c_risk_rate = (compas[compas.race == \"Caucasian\"].two_year_recid == 1).mean()\n",
    "print(f\"Caucasians Risk Rate: {c_risk_rate * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3cb963-8fdb-4596-a724-a72f4c01cf0c",
   "metadata": {},
   "source": [
    "#### 1.1.5. (7 pt) Create a confusion matrix (CM) comparing COMPAS predictions for recidivism (low risk/high risk you created above) and the actual two-year recidivism and interpret the results. In order to be on the same page, let’s call recidivists “positives”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5885f3f1-d558-45de-ba05-cdba2502512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.crosstab(compas.two_year_recid, compas.highscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743efb48-039a-4461-a370-106dcfe2ca1d",
   "metadata": {},
   "source": [
    "| | | | |\n",
    "| -------- | ------------: | ------:| -----:|\n",
    "|**Actual/Predicted** | Non Recidivists | Recidivists | Total |\n",
    "| Non Recidivists | 1872 | 923 | 2795 |\n",
    "| Recidivists | 881 | 1602 | 2483 | \n",
    "| | 2753 | 2525 | 5278 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e785df5-4bac-460f-99f0-31dcd50fd86a",
   "metadata": {},
   "source": [
    "#### 1.1.6. (7pt) Discuss the CM. What is accuracy? What percentage of low-risk individuals are wrongly classified as high risk? What about the way around?  \n",
    "\n",
    "#### Would you feel comfortable having a judge to use COMPAS to inform sentencing guidelines? What do you think, how well can judges perform the same task without COMPAS’s help? Are they better or worse? At what point would the error/misclassification risk be acceptable for you? Do you think the acceptable error rate should be the same for human judges and for algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b46bce9c-c2ba-48a3-aade-c4c4a5af4adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6582038651004168\n",
      "FPR: 33.02325581395349%\n",
      "FNR: 35.48127265404752%\n"
     ]
    }
   ],
   "source": [
    "TN = 1872\n",
    "FP = 923\n",
    "FN = 881\n",
    "TP = 1602\n",
    "acc = (TP + TN)/5278\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"FPR: {FP/2795 * 100}%\")\n",
    "print(f\"FNR: {FN/2483 * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd564299-8a2d-4e57-af6e-93e6b56476a8",
   "metadata": {},
   "source": [
    "I would not fell comfortable having a judge use compas to inform sentencing guidelines, having an accuracy of 0.6582 is low, since it means the algorithm only got 65.82% of the predictions correct. Also having 33.02% in FPR and 35.48% in FNR is both too high, since it meant that it usually misclassifies around one-thirds of low-risk people or high-risk people. I think a judge performs the same tasks better without COMPAS's help. In order to use compas, I would need the accuracy to be at least 96~98% and the FPR and FNR to be both lower than 3%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d15b0-3f65-4221-816a-ef6379068f21",
   "metadata": {},
   "source": [
    "### 1.2 Analysis by race (28pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de64d297-9dd1-4af2-a18e-bd0958b76b38",
   "metadata": {},
   "source": [
    "#### 1.2.1. (2pt) Compute the recidivism rate separately for high-risk and low risk African-Americans and Caucasians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9f248b-3273-449f-89e1-0cc06d82e42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Risk African American Recidivism Rate: 35.14115898959881%\n",
      "High Risk African American Recidivism Rate: 64.95352651722253%\n",
      "Low Risk Caucasian Recidivism Rate: 28.997867803837952%\n",
      "High Risk Caucasian Recidivism Rate: 59.48275862068966%\n"
     ]
    }
   ],
   "source": [
    "low_risk_aa_rate = (compas[(compas.highscore == 0) & (compas.race == \"African-American\")].two_year_recid == 1).mean()\n",
    "print(f\"Low Risk African American Recidivism Rate: {low_risk_aa_rate * 100}%\")\n",
    "high_risk_aa_rate = (compas[(compas.highscore == 1) & (compas.race == \"African-American\")].two_year_recid == 1).mean()\n",
    "print(f\"High Risk African American Recidivism Rate: {high_risk_aa_rate * 100}%\")\n",
    "low_risk_c_rate = (compas[(compas.highscore == 0) & (compas.race == \"Caucasian\")].two_year_recid == 1).mean()\n",
    "print(f\"Low Risk Caucasian Recidivism Rate: {low_risk_c_rate * 100}%\")\n",
    "high_risk_c_rate = (compas[(compas.highscore == 1) & (compas.race == \"Caucasian\")].two_year_recid == 1).mean()\n",
    "print(f\"High Risk Caucasian Recidivism Rate: {high_risk_c_rate * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cffd35c-99d2-404f-b556-5c73f1b68e09",
   "metadata": {},
   "source": [
    "#### 1.2.2. (6pt) Comment the results in the previous point. How similar are the rates for the the low- risk Caucasians and low-risk African Americans? For the high-risk Caucasians and high-risk African Americans? Do you see a racial disparity here? If yes, which group is it favoring? Based on these figures, do you think COMPAS is fair?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86478399-7159-4a67-ae1c-f34784aefb00",
   "metadata": {},
   "source": [
    "Overall the recidivism rate is higher for African Americans when compared with Caucasians. For low-risks, African American Recidivism Rate is higher by around 6.14% while for high-risks, African American Recidivism Rate is higher by 5.47%. I do see a racial disparity, Compas favors Caucasians, therefore based on these figures, COMPAS is not fair as it rates a group higher in both categorizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d319ce51-e494-41ed-b1b6-a1f1a542811a",
   "metadata": {},
   "source": [
    "#### 1.2.3. (6pt) Now repeat your confusion matrix calculation and analysis from 1.1.5. But this time do it separately for African-Americans and for Caucasians:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12da571a-a6cf-4301-9b50-677db97f6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_cm = pd.crosstab(compas[compas.race == \"African-American\"].two_year_recid, compas[compas.race == \"African-American\"].highscore)\n",
    "c_cm = pd.crosstab(compas[compas.race == \"Caucasian\"].two_year_recid, compas[compas.race == \"Caucasian\"].highscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e552ab-2659-401b-a69e-623e7ddbab10",
   "metadata": {},
   "source": [
    "| | **African American** | | |\n",
    "| -------- | ------------: | ------:| -----:|\n",
    "|**Actual/Predicted** | Non Recidivists | Recidivists | Total |\n",
    "| Non Recidivists | 873 | 641 | 1514 |\n",
    "| Recidivists | 473 | 1188 | 1661 | \n",
    "| | 1346 | 1829 | 3175 |\n",
    "\n",
    "| | **Caucasian** | | |\n",
    "| -------- | ------------: | ------:| -----:|\n",
    "|**Actual/Predicted** | Non Recidivists | Recidivists | Total |\n",
    "| Non Recidivists | 999 | 282 | 1281 |\n",
    "| Recidivists | 408 | 414 | 822 | \n",
    "| | 1407 | 696 | 2103 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad629ff7-193e-4241-a3d7-4bef7ab05984",
   "metadata": {},
   "source": [
    "#### (a) How accurate is the COMPAS classification for African-Americans and for Caucasians?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18b0ca29-debd-4350-baa2-a503b8d0e027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "African American Accuracy: 0.6491338582677165\n",
      "Caucasian Accuracy: 0.6718972895863052\n"
     ]
    }
   ],
   "source": [
    "aa_TN = 873\n",
    "aa_FP = 641\n",
    "aa_FN = 473\n",
    "aa_TP = 1188\n",
    "c_TN = 999\n",
    "c_FP = 282\n",
    "c_FN = 408\n",
    "c_TP = 414\n",
    "print(f\"African American Accuracy: {(aa_TP + aa_TN)/3175}\")\n",
    "print(f\"Caucasian Accuracy: {(c_TP + c_TN)/2103}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1239522-d655-439c-bd3c-d394370ce8fc",
   "metadata": {},
   "source": [
    "#### (b) What are the false positive rates (false recidivism rates) FPR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "904b6db1-22d6-49c6-97d9-eaa0ae75ca7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "African American FPR: 42.33817701453104%\n",
      "Caucasian FPR: 22.01405152224824%\n",
      "Diff: 20.3241254922828\n"
     ]
    }
   ],
   "source": [
    "print(f\"African American FPR: {aa_FP/1514 * 100}%\")\n",
    "print(f\"Caucasian FPR: {c_FP/1281 * 100}%\")\n",
    "print(f\"Diff: {(aa_FP/1514 * 100) - (c_FP/1281 * 100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ae576c-b7e3-4e35-b0a8-fa2b8a7899b3",
   "metadata": {},
   "source": [
    "#### (c) The false negative rates (false no-recidivism rates) FNR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9780c0ee-2610-4b87-94c4-7c8e79808155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "African American FNR: 28.47682119205298%\n",
      "Caucasian FNR: 49.63503649635037%\n",
      "Diff: -21.158215304297386\n"
     ]
    }
   ],
   "source": [
    "print(f\"African American FNR: {aa_FN/1661 * 100}%\")\n",
    "print(f\"Caucasian FNR: {c_FN/822 * 100}%\")\n",
    "print(f\"Diff: {(aa_FN/1661 * 100) - (c_FN/822 * 100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4990a-7319-4449-8721-5a613a97ffcc",
   "metadata": {},
   "source": [
    "#### 1.2.4. (6pt) If you have done this correctly, you will find that COMPAS’s percentage of correctly categorized individuals (accuracy) is fairly similar for African-Americans and Caucasians, but that false positive rates and false negative rates are different. In your opinion, is the COMPAS algorithm “fair”? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6800d10-7d81-4328-a9b8-e9c4d18fe6f3",
   "metadata": {},
   "source": [
    "No COMPAS is not fair because even though the accuracy is similar, COMPAS actually misclassified more low risk African American as High Risk and misclassifies more high risk Caucasians as low risk individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49caedb5-cbae-49e4-bc7e-09cfd280de91",
   "metadata": {},
   "source": [
    "#### 1.2.5. (8pt) Does your answer in 4 align with your answer in 2? Explain!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead38f05-6954-4220-be4f-9bb1a109ee8d",
   "metadata": {},
   "source": [
    "My answers align but the justification is different, after seperating the races, the analysis showed that COMPAS isn't fair because of the high disparity in FPR and FNR, such that it misclassified many low risk African Americans as high risk and high risk Caucasians as low risks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e234b-f558-4234-935c-3a5b771c760b",
   "metadata": {},
   "source": [
    "## 2. Can you beat COMPAS? (50pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fd6d1c-2836-4f3c-be3c-375868ec9f99",
   "metadata": {},
   "source": [
    "#### 2.1. Create the model (30pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea10c1-1147-40c0-ace5-e8c399cd97df",
   "metadata": {},
   "source": [
    "#### 2.1.1. (6pt) Before we start: what do you think, what is an appropriate model performance measure here? A, P, R, F or something else, such as FPR or FNR? Maybe you want to report multiple measures? Explain!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4800dc-cb45-4e5d-9efd-0e85da267050",
   "metadata": {},
   "source": [
    "I think accuracy, FPR, FNR are the three measures I should measure, because we need to see how well the model predicts the outcome, but also measure the amount of false positives and false negatives we have in order to see if our model is particular bias towards a race or gender."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcce532-0e1f-4df2-beb7-90feb55d315a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.2. (6pt) you should not use variable decile score that originates from COMPAS model. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983bb120-8353-4990-8afb-e29894dc4507",
   "metadata": {},
   "source": [
    "Decile score is COMPAS's prediction, since we aim to produce a better model than COMPAS, we shouldn't use the score the COMPAS predicted in our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12cbca5-c908-41e4-9846-71b144d4b50b",
   "metadata": {},
   "source": [
    "#### 2.1.3. (8pt) Now it is time to do the modeling. Create a logistic regression model that contains all explanatory variables you have in data into the model. (Some of these you have to convert to dummies). Do not include the variables discussed above, do not include race and gender in this model to avoid explicit gender/racial bias.\n",
    "\n",
    "#### Use 10-fold cross-validation (CV) to compute its relevant performance measure(s) you discussed above. Some basic code for CV is in Python Notes 13.2 Cross Validation background explanations are in the ISLR book Section 5.1 Cross-Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d96f696d-815d-46db-ad72-d285d9502965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6703291213846242\n",
      "FNR: 0.3838369607462107\n",
      "FPR: 0.28157962109575013\n"
     ]
    }
   ],
   "source": [
    "y = compas.two_year_recid\n",
    "X = compas.drop(columns=[\"two_year_recid\", \"sex\", \"race\", \"decile_score\", \"highscore\"])\n",
    "# X = compas.drop(columns=[\"two_year_recid\", \"sex\", \"race\", \"decile_score\", \"highscore\", \"age_cat\", \"age\"])\n",
    "X = pd.get_dummies(X, columns=[\"age_cat\", \"c_charge_degree\"])\n",
    "# X = pd.get_dummies(X, columns=[\"c_charge_degree\"])\n",
    "m = LogisticRegression(max_iter = 1000).fit(X, y)\n",
    "def convert(num):\n",
    "    l = []\n",
    "    for i in num:\n",
    "        l.append((i - 1) * -1)\n",
    "    return l\n",
    "X_inverted = X.copy()\n",
    "X_inverted[[\"age_cat_25 - 45\", \"age_cat_Greater than 45\", \"age_cat_Less than 25\", \"c_charge_degree_F\", \"c_charge_degree_M\"]] = X_inverted[[\"age_cat_25 - 45\", \"age_cat_Greater than 45\",\"age_cat_Less than 25\",\"c_charge_degree_F\", \"c_charge_degree_M\"]].apply(convert)\n",
    "# X_inverted[[\"c_charge_degree_F\", \"c_charge_degree_M\"]] = X_inverted[[\"c_charge_degree_F\", \"c_charge_degree_M\"]].apply(convert)\n",
    "y_inverted = convert(y)\n",
    "m_inverted = LogisticRegression(max_iter = 1000).fit(X_inverted, y_inverted)\n",
    "acc_cv = cross_val_score(m, X, y, scoring=\"accuracy\", cv=10).mean()\n",
    "FNR_cv = np.subtract(np.ones(10), cross_val_score(m, X, y, scoring=\"recall\", cv=10)).mean()\n",
    "FPR_cv = np.subtract(np.ones(10), cross_val_score(m_inverted, X_inverted, y_inverted, scoring=\"recall\", cv=10)).mean()\n",
    "print(f\"Accuracy: {acc_cv}\")\n",
    "print(f\"FNR: {FNR_cv}\")\n",
    "print(f\"FPR: {FPR_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d22625a-ae92-4243-9b70-f8cb6f353a8e",
   "metadata": {},
   "source": [
    "#### 4. (10pt) Experiment with different models to find the best model according to your performance indicator. Try trees and k-NN, you may also include other types of models. Include/exclude different variables. You may also do feature engineering, e.g. create a different set of age groups, include variables like age2, age3, interaction effects, etc. But do not include race and gender. Report what did you try (no need to report the full results of all of your unsuccessful attempts), and your best model’s performance. Did you got better results or worse results than COMPAS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50d02c3e-cb00-46c2-9ae1-c76222f51430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.646263872117762\n",
      "FNR: 0.45994299779764225\n",
      "FPR: 0.3313082437275986\n"
     ]
    }
   ],
   "source": [
    "mTree = DecisionTreeClassifier().fit(X, y)\n",
    "mTree_inverted = DecisionTreeClassifier().fit(X_inverted, y_inverted)\n",
    "acc_cv = cross_val_score(mTree, X, y, scoring=\"accuracy\", cv=10).mean()\n",
    "FNR_cv = np.subtract(np.ones(10), cross_val_score(mTree, X, y, scoring=\"recall\", cv=10)).mean()\n",
    "FPR_cv = np.subtract(np.ones(10), cross_val_score(mTree_inverted, X_inverted, y_inverted, scoring=\"recall\", cv=10)).mean()\n",
    "print(f\"Accuracy: {acc_cv}\")\n",
    "print(f\"FNR: {FNR_cv}\")\n",
    "print(f\"FPR: {FPR_cv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21f3a3b5-7771-482f-9934-dcbaa32cecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6263713989994826\n",
      "FNR: 0.44662844928099493\n",
      "FPR: 0.30876600102406554\n"
     ]
    }
   ],
   "source": [
    "mNeigh = KNeighborsClassifier().fit(X, y)\n",
    "mNeigh_inverted = KNeighborsClassifier().fit(X_inverted, y_inverted)\n",
    "acc_cv = cross_val_score(mNeigh, X, y, scoring=\"accuracy\", cv=10).mean()\n",
    "FNR_cv = np.subtract(np.ones(10), cross_val_score(mNeigh, X, y, scoring=\"recall\", cv=10)).mean()\n",
    "FPR_cv = np.subtract(np.ones(10), cross_val_score(mNeigh_inverted, X_inverted, y_inverted, scoring=\"recall\", cv=10)).mean()\n",
    "print(f\"Accuracy: {acc_cv}\")\n",
    "print(f\"FNR: {FNR_cv}\")\n",
    "print(f\"FPR: {FPR_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abe1a9-20ed-4f39-a9f4-00001a9fec27",
   "metadata": {},
   "source": [
    "I tried removing age and age_cat from the model, but the results turned out worse, my best results came from the logistics model having a higher accuracy of 0.6703 and worse FNR of 0.3838, but a better FPR of 0.2815."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a350af6-ab3e-498a-a3b6-beca950231a3",
   "metadata": {},
   "source": [
    "### 2.2 Is your model more fair? (20pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62ccc3f-6cb0-4563-afb7-1dcca40b4524",
   "metadata": {},
   "source": [
    "#### 2.2.1. (6pt) Now use your best model to predict the two-year recidivism risk, and compute the percentage of the predicted low-risk and high-risk individuals who recidivate, by race (replicate 1.2-1). Is your model more or less fair than COMPAS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54783e5e-4c57-4bbc-912a-67f8147fe2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "compas[\"predictions\"] = m.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26b1fff6-6725-4e3e-be97-0321626e9791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Risk African American Recidivism Rate: 33.10201249132547%\n",
      "High Risk African American Recidivism Rate: 68.28143021914647%\n",
      "Low Risk Caucasian Recidivism Rate: 31.183510638297875%\n",
      "High Risk Caucasian Recidivism Rate: 58.931552587646074%\n"
     ]
    }
   ],
   "source": [
    "low_risk_aa_rate = (compas[(compas.predictions == 0) & (compas.race == \"African-American\")].two_year_recid == 1).mean()\n",
    "print(f\"Low Risk African American Recidivism Rate: {low_risk_aa_rate * 100}%\")\n",
    "high_risk_aa_rate = (compas[(compas.predictions == 1) & (compas.race == \"African-American\")].two_year_recid == 1).mean()\n",
    "print(f\"High Risk African American Recidivism Rate: {high_risk_aa_rate * 100}%\")\n",
    "low_risk_c_rate = (compas[(compas.predictions == 0) & (compas.race == \"Caucasian\")].two_year_recid == 1).mean()\n",
    "print(f\"Low Risk Caucasian Recidivism Rate: {low_risk_c_rate * 100}%\")\n",
    "high_risk_c_rate = (compas[(compas.predictions == 1) & (compas.race == \"Caucasian\")].two_year_recid == 1).mean()\n",
    "print(f\"High Risk Caucasian Recidivism Rate: {high_risk_c_rate * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f36302f-67ac-491c-a283-1ec66036122c",
   "metadata": {},
   "source": [
    "The results were the same since African Americans have higher rates in both categories. However the difference in the Low Risk category was smaller, but the difference in the High Risk category was bigger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e788a153-607e-4b1b-bb8c-d83d4ca8573d",
   "metadata": {},
   "source": [
    "#### 2. (6pt) Compute FPR and FNR by race (replicate 1.2-3 the FNR/FPR question). Is your model more or less fair than COMPAS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "310b7862-4f07-4a9a-ae4a-9b3e40e76ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_cm = pd.crosstab(compas[compas.race == \"African-American\"].two_year_recid, compas[compas.race == \"African-American\"].predictions)\n",
    "c_cm = pd.crosstab(compas[compas.race == \"Caucasian\"].two_year_recid, compas[compas.race == \"Caucasian\"].predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21848737-6a38-43d7-934a-78c26132e0f3",
   "metadata": {},
   "source": [
    "| | **African American** | | |\n",
    "| -------- | ------------: | ------:| -----:|\n",
    "|**Actual/Predicted** | Non Recidivists | Recidivists | Total |\n",
    "| Non Recidivists | 964 | 550 | 1514 |\n",
    "| Recidivists | 477 | 1184 | 1661 | \n",
    "| | 1441 | 1734 | 3175 |\n",
    "\n",
    "| | **Caucasian** | | |\n",
    "| -------- | ------------: | ------:| -----:|\n",
    "|**Actual/Predicted** | Non Recidivists | Recidivists | Total |\n",
    "| Non Recidivists | 1035 | 246 | 1281 |\n",
    "| Recidivists | 469 | 353 | 822 | \n",
    "| | 1504 | 599 | 2103 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a0b29a7-6dd1-4a5b-81fd-1f139335b669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "African American FPR: 36.327608982826945%\n",
      "Caucasian FPR: 19.20374707259953%\n",
      "Diff: 17.123861910227415\n",
      "African American FNR: 28.717639975918118%\n",
      "Caucasian FPR: 57.05596107055961%\n",
      "Diff: -28.338321094641493\n"
     ]
    }
   ],
   "source": [
    "aa_TN = 964\n",
    "aa_FP = 550\n",
    "aa_FN = 477\n",
    "aa_TP = 1184\n",
    "c_TN = 1035\n",
    "c_FP = 246\n",
    "c_FN = 469\n",
    "c_TP = 353\n",
    "print(f\"African American FPR: {aa_FP/1514 * 100}%\")\n",
    "print(f\"Caucasian FPR: {c_FP/1281 * 100}%\")\n",
    "print(f\"Diff: {(aa_FP/1514 * 100) - (c_FP/1281 * 100)}\")\n",
    "print(f\"African American FNR: {aa_FN/1661 * 100}%\")\n",
    "print(f\"Caucasian FPR: {c_FN/822 * 100}%\")\n",
    "print(f\"Diff: {(aa_FN/1661 * 100) - (c_FN/822 * 100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bc9d0e-78c3-432b-83cb-aecea79c4611",
   "metadata": {},
   "source": [
    "#### 3. (8pt) Interpret your results from 2.2.1 and 2.2.2, and explain whether your model is any better (or worse) than COMPAS in terms of fairness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9290cf0-5648-4003-a7cf-a6860d08cb81",
   "metadata": {},
   "source": [
    "My model is slightly more fair in terms of the FPR rating, but more unfair in terms of FNR rating. My model is has a smaller difference in the FPR rating of the two races by around 3% but more unfair in te FNR rating by 7%. However my model is still unable to equalize the FPR ad the FNR of the two races, which means that my model is still unfair and is still misclassifying low risk African Americans as high risk and high risk caucasians as low risk. The highlight of my model is that it managed to decrease the FPR of both African American and Caucasian, and even decreased the FPR for African Americans even more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd449177-a413-447d-b9d6-28426282e21c",
   "metadata": {},
   "source": [
    "Around 4 hours"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
